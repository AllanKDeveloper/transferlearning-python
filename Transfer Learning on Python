{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxUbu0hKf10XVA7bECEBSz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllanKDeveloper/transferlearning-python/blob/main/Transfer%20Learning%20on%20Python\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "bVPP-8MpKsuo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "# URLs for dataset\n",
        "BASE_DIR = '/content/deepweeds'\n",
        "IMAGES_URL = \"https://drive.google.com/uc?export=download&id=1xnK3B6K6KekDI55vwJ0vnc2IGoDga9cj\"\n",
        "LABELS_URL = \"https://raw.githubusercontent.com/AlexOlsen/DeepWeeds/master/labels/labels.csv\"\n",
        "\n",
        "# Configuration\n",
        "INPUT_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "NUM_CLASSES = 9  # 8 weed species + 1 negative class\n",
        "\n",
        "# Create base directory in Colab\n",
        "os.makedirs(BASE_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar imagens do Google Drive\n",
        "!gdown 1xnK3B6K6KekDI55vwJ0vnc2IGoDga9cj --output {BASE_DIR}/images.zip\n",
        "\n",
        "# Verificar se o arquivo ZIP é válido\n",
        "zip_file = os.path.join(BASE_DIR, 'images.zip')\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.testzip()  # Testa se o arquivo ZIP está corrompido\n",
        "    print(\"O arquivo ZIP é válido, extraindo imagens...\")\n",
        "    # Extrair as imagens\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(BASE_DIR)\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"O arquivo {zip_file} não é um ZIP válido ou está corrompido.\")\n",
        "    # Se o arquivo ZIP não for válido, baixe-o novamente ou busque outra fonte para o dataset\n",
        "    raise\n",
        "\n",
        "# Baixar os rótulos\n",
        "print(\"Downloading labels...\")\n",
        "labels_df = pd.read_csv(LABELS_URL)\n",
        "\n",
        "# Exibir as primeiras linhas do DataFrame para verificar as colunas\n",
        "print(labels_df.head())\n",
        "\n",
        "# Verificar se as colunas esperadas existem\n",
        "if 'Filename' not in labels_df.columns or 'Label' not in labels_df.columns:\n",
        "    raise KeyError(\"As colunas 'Filename' ou 'Label' não foram encontradas no DataFrame!\")\n",
        "\n",
        "# Adicionar caminho completo das imagens\n",
        "labels_df['image_path'] = BASE_DIR + '/' + labels_df['Filename']\n",
        "\n",
        "# Converter os rótulos para string, pois o class_mode='categorical' espera valores em string\n",
        "labels_df['Label'] = labels_df['Label'].astype(str)\n",
        "\n",
        "# Garantir que cada valor da coluna 'Label' seja uma lista de uma string (para compatibilidade com o flow_from_dataframe)\n",
        "labels_df['Label'] = labels_df['Label'].apply(lambda x: [x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNS_1VU7K7OQ",
        "outputId": "8483d2f2-4142-4490-db59-ea0216035e14"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1xnK3B6K6KekDI55vwJ0vnc2IGoDga9cj\n",
            "From (redirected): https://drive.google.com/uc?id=1xnK3B6K6KekDI55vwJ0vnc2IGoDga9cj&confirm=t&uuid=ec767ee2-39e9-488b-af07-f2afa04bb398\n",
            "To: /content/deepweeds/images.zip\n",
            "100% 492M/492M [00:06<00:00, 78.1MB/s]\n",
            "O arquivo ZIP é válido, extraindo imagens...\n",
            "Downloading labels...\n",
            "                Filename  Label       Species\n",
            "0  20160928-140314-0.jpg      0  Chinee apple\n",
            "1  20160928-140337-0.jpg      0  Chinee apple\n",
            "2  20160928-140731-0.jpg      0  Chinee apple\n",
            "3  20160928-140747-0.jpg      0  Chinee apple\n",
            "4  20160928-141107-0.jpg      0  Chinee apple\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir em treino e validação\n",
        "train_df, val_df = train_test_split(labels_df, test_size=0.2, stratify=labels_df['Label'], random_state=42)\n",
        "\n",
        "# Geradores de dados para treino e validação\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normaliza as imagens\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)  # Normaliza as imagens de validação\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='image_path',\n",
        "    y_col='Label',\n",
        "    target_size=INPUT_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col='image_path',\n",
        "    y_col='Label',\n",
        "    target_size=INPUT_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O6rIwVOUiVl",
        "outputId": "e0eeb7bf-a622-4d4f-946b-bf613a733316"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14007 validated image filenames belonging to 9 classes.\n",
            "Found 3502 validated image filenames belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construção do modelo com Transfer Learning\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Congela os pesos do modelo base\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilação do modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "i3JlGcZyUk4k"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinamento do modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVq4_J_PUoFG",
        "outputId": "4429dff3-f7b0-4401-f85b-4856f46afb8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 95/438\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19:08\u001b[0m 3s/step - accuracy: 0.5106 - loss: 1.7811"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação e visualização dos resultados\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Treino')\n",
        "plt.plot(history.history['val_accuracy'], label='Validação')\n",
        "plt.title('Acurácia')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Treino')\n",
        "plt.plot(history.history['val_loss'], label='Validação')\n",
        "plt.title('Perda')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2o6URGaUq1F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}